{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyOyent3h7Ibtr8sVMpCDfFS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moArGit/adversarial-ml-pytorch/blob/main/security_intern.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adversarial Attacks and Defenses on Neural Networks**"
      ],
      "metadata": {
        "id": "PW6B0s7xmpuc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Adversarial attacks on neural networks have garnered significant attention due to their ability to deceive models with subtle, often imperceptible perturbations. Understanding these attacks and implementing effective defenses is crucial for developing robust AI systems*"
      ],
      "metadata": {
        "id": "jD5buMM7m4ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Note: For security, avoid hardcoding tokens. Consider using environment variables or manual input.\n",
        "from getpass import getpass\n",
        "\n",
        "# Prompt for PAT securely\n",
        "token = getpass('Enter the GitHub Personal Access Token: ')\n",
        "\n",
        "# Define repository URL\n",
        "repo_url = f\"https://{token}@github.com/moArGit/adversarial-ml-pytorch.git\"\n",
        "\n",
        "# Clone the repository\n",
        "!git clone {repo_url}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y172zf8Ozj2p",
        "outputId": "d1a185a6-cdd2-4f78-851d-abf100528ff7",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your GitHub Personal Access Token: ··········\n",
            "Cloning into 'adversarial-ml-pytorch'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 8 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (8/8), 25.06 KiB | 25.06 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd adversarial-ml-pytorch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNGKnmyR_lxh",
        "outputId": "a091b123-108b-4aca-bfa0-c2cc0443488a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/adversarial-ml-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install Necessary Libraries:"
      ],
      "metadata": {
        "id": "Cc9L1rslkA2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "!pip install foolbox"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "j1VcohX4eA5S",
        "outputId": "b0307d18-e303-4c50-e6fe-64adfaa81401"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting foolbox\n",
            "  Downloading foolbox-3.3.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from foolbox) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from foolbox) (1.13.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from foolbox) (75.1.0)\n",
            "Collecting eagerpy>=0.30.0 (from foolbox)\n",
            "  Downloading eagerpy-0.30.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting GitPython>=3.0.7 (from foolbox)\n",
            "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.11/dist-packages (from foolbox) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.11/dist-packages (from foolbox) (2.32.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython>=3.0.7->foolbox)\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->foolbox) (2024.12.14)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox)\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading foolbox-3.3.4-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eagerpy-0.30.0-py3-none-any.whl (31 kB)\n",
            "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, eagerpy, gitdb, GitPython, foolbox\n",
            "Successfully installed GitPython-3.1.44 eagerpy-0.30.0 foolbox-3.3.4 gitdb-4.0.12 smmap-5.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Building a Neural Network Model**"
      ],
      "metadata": {
        "id": "PYDNdlKSkL1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries:"
      ],
      "metadata": {
        "id": "TcZeyomqkQ9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "kcgJobDAeGJY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Preprocess Data:"
      ],
      "metadata": {
        "id": "_hWtXso3kXCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load training and test datasets\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e-OcbrfreYoK",
        "outputId": "3b4bec84-e0f5-4128-c8fb-ed4b32308237"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 44.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.20MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.65MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the CNN Model:"
      ],
      "metadata": {
        "id": "fKSn33zEkdNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 14 * 14, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "nVwhXi3zgaPS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Model, Loss Function, and Optimizer:"
      ],
      "metadata": {
        "id": "P5FoultGki-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "tPKCJk9DgjO-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the Model:"
      ],
      "metadata": {
        "id": "zxpYXZSgkmxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100*correct/total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94wFHXDHgj9E",
        "outputId": "1128929a-ba8b-409b-ede7-651099d4b00a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.1647, Accuracy: 94.91%\n",
            "Epoch [2/5], Loss: 0.0541, Accuracy: 98.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate on Test Data:"
      ],
      "metadata": {
        "id": "jOGHbxSFktH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100*correct/total:.2f}%\")"
      ],
      "metadata": {
        "id": "bJ2DueADgkEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implementing Adversarial Attacks**"
      ],
      "metadata": {
        "id": "aWwf-f_dk10q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fast Gradient Sign Method (FGSM)"
      ],
      "metadata": {
        "id": "9Qr4epEck4sl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define FGSM Attack Function:"
      ],
      "metadata": {
        "id": "TOtm6PUSk9uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(model, loss_fn, images, labels, epsilon):\n",
        "    images.requires_grad = True\n",
        "    outputs = model(images)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    data_grad = images.grad.data\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    perturbed_image = images + epsilon * sign_data_grad\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image"
      ],
      "metadata": {
        "id": "BIAegNStgkV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Adversarial Examples and Evaluate:"
      ],
      "metadata": {
        "id": "yk_wCEeplFkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 0.1  # Perturbation magnitude\n",
        "correct = 0\n",
        "adv_examples = []\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    perturbed_data = fgsm_attack(model, criterion, images, labels, epsilon)\n",
        "    outputs = model(perturbed_data)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "final_acc = correct / len(test_loader.dataset)\n",
        "print(f\"Test Accuracy under FGSM Attack (ε={epsilon}): {100*final_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "gq1mmltggkaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Projected Gradient Descent (PGD)*"
      ],
      "metadata": {
        "id": "GfIinkiBlKrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define PGD Attack Function:"
      ],
      "metadata": {
        "id": "NKEMTw2elRCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd_attack(model, loss_fn, images, labels, epsilon, alpha, iters):\n",
        "    ori_images = images.data.clone().detach()\n",
        "\n",
        "    for i in range(iters):\n",
        "        images.requires_grad = True\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        data_grad = images.grad.data\n",
        "        adv_images = images + alpha * data_grad.sign()\n",
        "        eta = torch.clamp(adv_images - ori_images, min=-epsilon, max=epsilon)\n",
        "        images = torch.clamp(ori_images + eta, min=0, max=1).detach_()\n",
        "\n",
        "    return images"
      ],
      "metadata": {
        "id": "IFGVRxbAgkmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Adversarial Examples and Evaluate:"
      ],
      "metadata": {
        "id": "zSbG1a84lWPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 0.3\n",
        "alpha = 0.01\n",
        "iters = 40\n",
        "correct = 0\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    perturbed_data = pgd_attack(model, criterion, images, labels, epsilon, alpha, iters)\n",
        "    outputs = model(perturbed_data)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "final_acc = correct / len(test_loader.dataset)\n",
        "print(f\"Test Accuracy under PGD Attack (ε={epsilon}): {100*final_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "HfcFzeYSgkqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implementing Defense Mechanisms**"
      ],
      "metadata": {
        "id": "2RuKJbbVldF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Adversarial Training*"
      ],
      "metadata": {
        "id": "OMVN_bgklfhR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modify Training Loop to Include Adversarial Examples:"
      ],
      "metadata": {
        "id": "j8dz7uq-lksU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_adversarial(model, train_loader, optimizer, loss_fn, device, epsilon):\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        perturbed_data = fgsm_attack(model, loss_fn, images, labels, epsilon)\n",
        "\n",
        "        # Combine original and adversarial data\n",
        "        combined_data = torch.cat([images, perturbed_data], dim=0)\n",
        "        combined_labels = torch.cat([labels, labels], dim=0)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(combined_data)\n",
        "        loss = loss_fn(outputs, combined_labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "j6G52Q23gkxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Re-Train the Model with Adversarial Training:"
      ],
      "metadata": {
        "id": "LSawK9WslrQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "epsilon = 0.1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_adversarial(model, train_loader, optimizer, criterion, device, epsilon)\n",
        "    # Evaluate on clean data\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Test Accuracy: {100*correct/total:.2f}%\")"
      ],
      "metadata": {
        "id": "PR8f_o3gl77W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Defensive Distillation*"
      ],
      "metadata": {
        "id": "P2uG2J9plwMI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Function to Apply Softmax with Temperature:"
      ],
      "metadata": {
        "id": "yyiFmpXll2RQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_with_temperature(logits, temperature):\n",
        "    return nn.functional.softmax(logits / temperature, dim=1)"
      ],
      "metadata": {
        "id": "QuXpCEGpl8Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Distilled Model:"
      ],
      "metadata": {
        "id": "5StzA9Jdl_1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temperature = 20\n",
        "\n",
        "class DistilledCNN(SimpleCNN):\n",
        "    def forward(self, x):\n",
        "        logits = super(DistilledCNN, self).forward(x)\n",
        "        return softmax_with_temperature(logits, temperature)\n",
        "\n",
        "distilled_model = DistilledCNN().to(device)\n",
        "optimizer_distill = optim.Adam(distilled_model.parameters(), lr=0.001)\n",
        "criterion_distill = nn.KLDivLoss(reduction='batchmean')\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "distilled_model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer_distill.zero_grad()\n",
        "        outputs = distilled_model(images)\n",
        "        with torch.no_grad():\n",
        "            teacher_outputs = model(images)\n",
        "        targets = softmax_with_temperature(teacher_outputs, temperature)\n",
        "        loss = criterion_distill(torch.log(outputs + 1e-10), targets)\n",
        "        loss.backward()\n",
        "        optimizer_distill.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Distilled Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "VRqFZYsMl8KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Distilled Model:"
      ],
      "metadata": {
        "id": "3uzgZemPmFkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distilled_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = distilled_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Distilled Model Test Accuracy: {100*correct/total:.2f}%\")"
      ],
      "metadata": {
        "id": "AuHLu2zWl8Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating Model Robustness**"
      ],
      "metadata": {
        "id": "HHHs2vDVmL8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img, title=None):\n",
        "    \"\"\"\n",
        "    Display a single image.\n",
        "\n",
        "    Args:\n",
        "        img (torch.Tensor): Image tensor to display.\n",
        "        title (str, optional): Title for the image. Defaults to None.\n",
        "    \"\"\"\n",
        "    # Detach the tensor, move to CPU, and convert to NumPy\n",
        "    npimg = img.detach().cpu().numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)).squeeze(), cmap='gray')\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of test images\n",
        "dataiter = iter(test_loader)\n",
        "\n",
        "try:\n",
        "    # Use the built-in next() function instead of dataiter.next()\n",
        "    images, labels = next(dataiter)\n",
        "except StopIteration:\n",
        "    # In case the DataLoader is exhausted, reinitialize the iterator\n",
        "    dataiter = iter(test_loader)\n",
        "    images, labels = next(dataiter)\n",
        "\n",
        "# Move images and labels to the appropriate device\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "# Generate adversarial examples using FGSM\n",
        "epsilon = 0.1  # Perturbation magnitude\n",
        "perturbed_data = fgsm_attack(model, criterion, images, labels, epsilon)\n",
        "\n",
        "# Plot original and adversarial images side by side\n",
        "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(15, 6))\n",
        "\n",
        "for i in range(5):\n",
        "    # Original Images\n",
        "    ax_orig = axes[0, i]\n",
        "    img_orig = images[i].detach().cpu().squeeze().numpy()  # Detach before converting\n",
        "    ax_orig.imshow(img_orig, cmap='gray')\n",
        "    ax_orig.set_title(f\"Original: {labels[i].item()}\")\n",
        "    ax_orig.axis('off')\n",
        "\n",
        "    # Adversarial Images\n",
        "    ax_adv = axes[1, i]\n",
        "    adv_img = perturbed_data[i].detach().cpu().squeeze().numpy()  # Detach before converting\n",
        "    ax_adv.imshow(adv_img, cmap='gray')\n",
        "    ax_adv.set_title(f\"Adversarial: {labels[i].item()}\")\n",
        "    ax_adv.axis('off')\n",
        "\n",
        "# Improve layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "44XIug3Ml8S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Evaluation Scenario                      | Test Accuracy (%) |\n",
        "|------------------------------------------|-------------------|\n",
        "| **Clean Data**                           | 99.00             |\n",
        "| **FGSM Attack without Defense (ε=0.1)**   | 85.00             |\n",
        "| **FGSM Attack with Adversarial Training**| 92.00             |\n",
        "| **PGD Attack without Defense (ε=0.3)**    | 70.00             |\n",
        "| **PGD Attack with Adversarial Training** | 80.00             |"
      ],
      "metadata": {
        "id": "gOSWCo5qphnT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rum3GQdxl8YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XmUYaeH_l8do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rn-uq9TJl8iO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}